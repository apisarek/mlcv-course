{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_path = './facesYale.mat'\n",
    "faces = loadmat(faces_path)\n",
    "\n",
    "person_train = faces['personTrain']\n",
    "faces_train = faces['facesTrain']\n",
    "features_train = faces['featuresTrain']\n",
    "\n",
    "\n",
    "person_test = faces['personTest']\n",
    "faces_test = faces['facesTest']\n",
    "features_test = faces['featuresTest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase_path = './spambase.mat'\n",
    "spambase = loadmat(spambase_path)\n",
    "\n",
    "spam_features_train = spambase['featuresTrain']\n",
    "spam_features_test = spambase['featuresTest']\n",
    "spam_classes_train = spambase['classesTrain']\n",
    "spam_classes_test = spambase['classesTest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypercubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypercubes_path = './multiDimHypercubes.mat'\n",
    "hypercubes = loadmat(hypercubes_path)\n",
    "\n",
    "hyper_features_train_set = hypercubes['featuresTrain']\n",
    "hyper_features_test_set = hypercubes['featuresTest']\n",
    "hyper_classes_train_set = hypercubes['classesTrain']\n",
    "hyper_classes_test_set = hypercubes['classesTest']\n",
    "\n",
    "generator = list(zip(\n",
    "    hyper_features_train_set[0],\n",
    "    hyper_features_test_set[0],\n",
    "    hyper_classes_train_set[0],\n",
    "    hyper_classes_test_set[0],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(things):\n",
    "    plt.scatter(range(1, len(things) + 1), things)\n",
    "    plt.plot()\n",
    "    \n",
    "def euclid_dist(train_examples, test_example):\n",
    "    return np.sqrt(np.sum((train_examples - test_example)**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define nearest_neighbor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(train_features, test_features, train_classes):\n",
    "    if test_features.ndim == 1:\n",
    "        test_features = np.expand_dims(test_features, axis=0)\n",
    "    results = []\n",
    "    for test_example in test_features:\n",
    "        distances = euclid_dist(train_features, test_example)\n",
    "        results.append(train_classes[np.argmin(distances)])\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_pred = nearest_neighbor(features_train, features_test, person_train)\n",
    "acc_score = accuracy_score(person_test, persons_pred)\n",
    "error = 1 - acc_score\n",
    "print(f\"Error on test faces set: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for alpha in range(1, 21):\n",
    "    features_train_temp = features_train.copy()\n",
    "    features_test_temp = features_test.copy()\n",
    "    \n",
    "    features_train_temp[:,-1] *= alpha\n",
    "    features_test_temp[:,-1] *= alpha\n",
    "    \n",
    "    persons_pred = nearest_neighbor(features_train_temp, features_test_temp, person_train)\n",
    "    acc_score = accuracy_score(person_test, persons_pred)\n",
    "    accuracies.append(acc_score)\n",
    "errors = 1 - np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "As we can see on the graph, increasing the `alpha` parameters increases the total error on test test.\n",
    "Increasing `alpha` increases the length of distance component along that axis. It diminishes the impact of other features in the calculated distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_pred = nearest_neighbor(spam_features_train, spam_features_test, spam_classes_train)\n",
    "acc = accuracy_score(spam_classes_test, spam_pred)\n",
    "print(f\"Accuracy score on test spam set: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_features_all = np.concatenate([spam_features_train, spam_features_test])\n",
    "spam_classes_all = np.concatenate([spam_classes_train, spam_classes_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prepare boolean mask for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_len = len(spam_features_all)\n",
    "folds = np.linspace(0, spam_len, 6)\n",
    "mask = np.zeros((spam_len), dtype=np.bool)\n",
    "mask[:int(round(folds[1]))] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial  in range(10):   \n",
    "    for k in range(5):\n",
    "        np.random.shuffle(mask)\n",
    "        test_feature = spam_features_all[mask]\n",
    "        train_feature = spam_features_all[~mask]\n",
    "        test_classes = spam_classes_all[mask]\n",
    "        train_classes = spam_classes_all[~mask]\n",
    "        spam_pred = nearest_neighbor(train_feature, test_feature, train_classes)\n",
    "        acc = accuracy_score(test_classes, spam_pred)\n",
    "        print(f\"Accuracy score on fold {k} in trial {trial}: {acc}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "The accuracy scores have comparable value, all of them oscillate around ~90%. The error here is much smaller here, because in the original training/test set split the training set was ~20x smaller than the test set (what is really strange)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypercubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for dim, dataset in enumerate(generator, 1):\n",
    "    hyper_features_train,    hyper_features_test, \\\n",
    "    hyper_classes_train,    hyper_classes_test = dataset\n",
    "    predictions = nearest_neighbor(\n",
    "        hyper_features_train,\n",
    "        hyper_features_test,\n",
    "        hyper_classes_train\n",
    "    )\n",
    "    error = 1 - accuracy_score(hyper_classes_test, predictions)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "We can see that the overall error increases with increasing the dimension. This is known in machine learning as `curse of dimensionality`. It decreases the predictive power of models since we need more and more data to fill the space effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_min_distances_same = []\n",
    "mean_min_distances_opposite = []\n",
    "for dim, dataset in enumerate(generator, 1):\n",
    "    hyper_features_train,    hyper_features_test, \\\n",
    "    hyper_classes_train,    hyper_classes_test = dataset\n",
    "    \n",
    "    features_zero = hyper_classes_train[~hyper_classes_train]\n",
    "    features_one = hyper_classes_train[hyper_classes_train]\n",
    "    \n",
    "    min_distances_same = []\n",
    "    min_distances_opposite = []\n",
    "    \n",
    "    for test_example, test_class in zip(hyper_features_test, hyper_classes_test):\n",
    "        train_features_same = features_one if test_class else features_zero\n",
    "        train_features_opposite = features_one if not test_class else features_zero\n",
    "        \n",
    "        distances_same = euclid_dist(train_features_same, test_example)\n",
    "        distances_opposite = euclid_dist(train_features_opposite, test_example)\n",
    "\n",
    "        min_distances_same.append(distances_same.min())\n",
    "        min_distances_opposite.append(distances_opposite.min())\n",
    "    \n",
    "    mean_min_distances_same.append(np.array(min_distances_same).mean())\n",
    "    mean_min_distances_opposite.append(np.array(min_distances_opposite).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mean_min_distances_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mean_min_distances_opposite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "We can see on the graphs above that the average min distance to examples with the same / opposite class decreases with dimension. That is also due to `curse of dimensionality`. Euclidean distance has such a property that there is little difference in the distances between different pairs of examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = np.array(mean_min_distances_same) / np.array(mean_min_distances_opposite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipython nbconvert K-NN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
